{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification: cats & dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Handle imports up-front\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Silence logging messages from TensorFlow, except errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "# Use a specific GPU, if desired\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "# PyPI imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as image\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Figure out if we are running on Kaggle or not, if so\n",
    "# add the location of utils.py to path so we can import\n",
    "path_list=os.getcwd().split(os.sep)\n",
    "\n",
    "if path_list[1] == 'kaggle':\n",
    "    sys.path.append('/kaggle/usr/lib/image_classification_functions')\n",
    "\n",
    "# Import custom helper functions from utils.py\n",
    "from image_classification_functions import prep_data\n",
    "from image_classification_functions import single_training_run\n",
    "from image_classification_functions import plot_single_training_run\n",
    "from image_classification_functions import hyperparameter_optimization_run\n",
    "from image_classification_functions import plot_hyperparameter_optimization_run\n",
    "\n",
    "# Silence logging messages from TensorFlow, except errors\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Limit TensorFlow's CPU usage\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Decompress and organize the images\n",
    "training_data_path, validation_data_path, testing_data_path=prep_data()\n",
    "\n",
    "# Get lists of training and validation dog and cat images\n",
    "training_dogs=glob.glob(f'{training_data_path}/dogs/dog.*')\n",
    "training_cats=glob.glob(f'{training_data_path}/cats/cat.*')\n",
    "validation_dogs=glob.glob(f'{validation_data_path}/dogs/dog.*')\n",
    "validation_cats=glob.glob(f'{validation_data_path}/cats/cat.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot some of the cat and dog images\n",
    "fig, axs=plt.subplots(3,2,figsize=(6, 4))\n",
    "\n",
    "for cat, dog, row in zip(training_cats, training_dogs, axs):\n",
    "    for animal, ax in zip([cat, dog], row):\n",
    "        animal=image.load_img(animal)\n",
    "        animal=image.img_to_array(animal)\n",
    "        animal/=255.0\n",
    "        ax.imshow(animal)\n",
    "        ax.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Let's take a deeper look at a few of our images to get a feel for how image data is structured.\n",
    "\n",
    "### 2.1. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load one of the dogs\n",
    "dog=image.load_img(training_dogs[0])\n",
    "\n",
    "# And convert it to an array - this is how TensorFlow will handel the data\n",
    "dog=image.img_to_array(dog)\n",
    "\n",
    "# Take a look at some properties of the object\n",
    "print(f'Image data is: {type(dog)}')\n",
    "print(f'Image data shape: {dog.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has shape of 375 x 499 x 3? The image is 375 x 499 pixels, that makes sense. But what is the 3? Let's plot the pixel values and you will see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.hist(dog[:,:,0].flatten(), bins=100, color='red', alpha=0.5, label='Red channel')\n",
    "plt.hist(dog[:,:,1].flatten(), bins=100, color='green', alpha=0.5, label='Green channel')\n",
    "plt.hist(dog[:,:,2].flatten(), bins=100, color='blue', alpha=0.5, label='Blue channel')\n",
    "plt.xlabel('Pixel value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few interesting observations we can make here:\n",
    "\n",
    "1. This array has 3 axes: 375 x 499 x 3. The first two are the dimensions of the image, the third is the three color channels: red, green and blue.\n",
    "2. 375 x 499 x 3 is over a half million individual values - this one image is 10 time more data that any of the other datasets we have worked with so far!\n",
    "3. The range of pixel values is from 0 to about 250 - in reality it is (0,255) for a total range of 256 possible values per pixel. This is defined by the JPEG image standard.\n",
    "\n",
    "There are two things we can do with this information. First, we should scale the pixel values, this will improve the training of our neural network. We can do this directly in the model definition by adding a normalization layer. Second, we can make the images gray scale, which will decrease the input size and therefore computational burden by a factor of three. We can do this via the image dataset generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Image dimensions\n",
    "\n",
    "Let's take a look at a random sample of images from the dataset and see what their dimensions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get a random sample of images, half cats and half dogs\n",
    "sample_size=100\n",
    "sample=random.sample(training_dogs, sample_size//2)\n",
    "sample+=random.sample(training_cats, sample_size//2)\n",
    "\n",
    "# Collectors for data\n",
    "heights=[]\n",
    "widths=[]\n",
    "\n",
    "# Loop on the sample images\n",
    "for sample_image in sample:\n",
    "\n",
    "    # Load the image and convert it to an array\n",
    "    sample_image=image.load_img(sample_image)\n",
    "    sample_image=image.img_to_array(sample_image)\n",
    "\n",
    "    # Get the width and height and add to collections\n",
    "    heights.append(sample_image.shape[0])\n",
    "    widths.append(sample_image.shape[1])\n",
    "\n",
    "# Plot results as a histogram\n",
    "plt.hist(heights, bins=50, alpha=0.5, label='Image heights')\n",
    "plt.hist(widths, bins=50, alpha=0.5, label='Image widths')\n",
    "plt.xlabel('Image dimension')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above plot, let's set our image dimension at 64 or 128 pixels. Smaller is better for training speed and memory use, but we don't want to go too small, then the model will have a hard time learning from the data. There is no hard and fast rule here. You could do an experiment testing several different image dimensions to see how small we could make the image and still get good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Image aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the sample image aspect ratios\n",
    "aspect_ratios=np.array(widths)/np.array(heights)\n",
    "\n",
    "# Plot as histogram\n",
    "plt.hist(aspect_ratios, bins=50, color='black')\n",
    "plt.xlabel('Image aspect ratio')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common aspect ratio in the data set looks to be around 1.3 - which is the '4:3' aspect ratio that used to be the standard for computer monitors. Rather than using square input images, we can use this aspect ratio to better match the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Now it's time to build and train the model. We will do this in a few steps, evaluating performance by looking at the training curves along the way:\n",
    "\n",
    "1. Establish baseline performance with default settings\n",
    "2. Optimize the batch size and learning rate\n",
    "3. Optimize regularization with L1 and L2 penalties\n",
    "4. Optimize input image size for speed and/or better performance\n",
    "5. Optimize network architecture\n",
    "6. Final model and evaluation\n",
    "\n",
    "### 3.1. Baseline model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Do a single training run with default settings\n",
    "training_results=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    image_width=64,\n",
    "    aspect_ratio=4/3,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "training_results.model.summary()\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, not great. Does not seem like the model is learning at all. The training curves are jumping all over the place centered around 50% accuracy - the model is just guessing. This likely indicates that the learning rate is too large and/or the batch size is too small. Let's optimize those hyperparameters first.\n",
    "\n",
    "### 3.2. Batch size and learning rate optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters={\n",
    "    'batch_sizes': [8, 16, 32],\n",
    "    'learning_rates': [0.01, 0.001, 0.0001],\n",
    "    'image_widths': [64],\n",
    "    'aspect_ratio': 4/3,\n",
    "    'epochs': 20\n",
    "}\n",
    "\n",
    "# Train the model with each set of hyperparameters\n",
    "hyperparameter_optimization_results=hyperparameter_optimization_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Specify which hyperparameters to include in the plot labels\n",
    "plot_labels=['batch_sizes', 'learning_rates']\n",
    "\n",
    "# Plot the learning curves\n",
    "plot_hyperparameter_optimization_run(\n",
    "    hyperparameter_optimization_results,\n",
    "    hyperparameters,\n",
    "    plot_labels,\n",
    "    accuracy_ylims=[45,80],\n",
    "    entropy_ylims=[0.4,0.8]\n",
    ").show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training curves, it looks like the best results are obtained with a batch size of 256 and a learning rate of 0.001. That conclusion is somewhat subjective and based on how close the training and validation score curves are to each other, their smoothness and the final performance achieved at the end of the test run. We also need to consider computational resources. Continued experiments with a batch size to 256 will take longer than with a batch size of 128. The best philosophy after a first experiment is to take the smallest/fastest result that is acceptable and use it for continued testing.\n",
    "\n",
    "Let's use the best batch size and learning rate settings and train the model for longer to see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set some hyperparameters for the run\n",
    "hyperparameters={\n",
    "    'image_width': 64,\n",
    "    'aspect_ratio': 4/3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 200\n",
    "}\n",
    "\n",
    "# Do a single training run\n",
    "training_results=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Much better. But we are clearly over fitting - let's add some regularization.\n",
    "\n",
    "### 3.3. Regularization\n",
    "\n",
    "Optimize L1 and L2 penalties using the optimized batch size and learning rate from the previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters={\n",
    "    'l1_penalties': [0.01, 0.001, 0.0001],\n",
    "    'l2_penalties': [0.01, 0.001, 0.0001],\n",
    "    'batch_sizes': [64],\n",
    "    'learning_rates': [0.001],\n",
    "    'image_widths': [64],\n",
    "    'aspect_ratio': 4/3,\n",
    "    'epochs': 200\n",
    "}\n",
    "\n",
    "# Train the model with each set of hyperparameters\n",
    "hyperparameter_optimization_results=hyperparameter_optimization_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Specify which hyperparameters to include in the plot labels\n",
    "plot_labels=['l1_penalties', 'l2_penalties']\n",
    "\n",
    "# Plot the learning curves\n",
    "plot_hyperparameter_optimization_run(\n",
    "    hyperparameter_optimization_results,\n",
    "    hyperparameters,\n",
    "    plot_labels,\n",
    "    accuracy_ylims=[45,90],\n",
    "    entropy_ylims=[0.01,4.0]\n",
    ").show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set some hyperparameters for the run\n",
    "hyperparameters={\n",
    "    'l1_penalty': 0.001,\n",
    "    'l2_penalty': 0.01,\n",
    "    'image_width': 64,\n",
    "    'aspect_ratio': 4/3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 500\n",
    "}\n",
    "\n",
    "# Do a single training run\n",
    "training_results=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters,\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Input image size optimization\n",
    "\n",
    "Try some smaller input image sizes and see how the model does with the hyperparameter settings we have chosen via optimization so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters={\n",
    "    'l1_penalties': [0.001],\n",
    "    'l2_penalties': [0.01],\n",
    "    'batch_sizes': [64],\n",
    "    'learning_rates': [0.0001],\n",
    "    'image_widths': [32, 64, 128],\n",
    "    'aspect_ratio': 4/3,\n",
    "    'epochs': 300\n",
    "}\n",
    "\n",
    "# Train the model with each combination of hyperparameters\n",
    "hyperparameter_optimization_results=hyperparameter_optimization_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Specify which hyperparameters to include in the plot labels\n",
    "plot_labels=['image_widths']\n",
    "\n",
    "# Plot the training curves\n",
    "plot_hyperparameter_optimization_run(\n",
    "    hyperparameter_optimization_results,\n",
    "    hyperparameters,\n",
    "    plot_labels,\n",
    "    accuracy_ylims=[45,80],\n",
    "    entropy_ylims=[0.01,10.0]\n",
    ").show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set some hyperparameters for the run\n",
    "hyperparameters={\n",
    "    'l1_penalty': 0.001,\n",
    "    'l2_penalty': 0.01,\n",
    "    'image_width': 128,\n",
    "    'aspect_ratio': 4/3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 500\n",
    "}\n",
    "\n",
    "# Do a single training run\n",
    "training_results=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters)\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model architecture\n",
    "\n",
    "#### 3.5.1. Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters={\n",
    "    'filter_nums_list': [[32,64,128],[64,128,256],[128,256,512]],\n",
    "    'filter_sizes': [4,5,6],\n",
    "    'l1_penalties': [0.001],\n",
    "    'l2_penalties': [0.01],\n",
    "    'batch_sizes': [64],\n",
    "    'learning_rates': [0.0001],\n",
    "    'image_widths': [128],\n",
    "    'aspect_ratio': 4/3,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "# Train the model with each combination of hyperparameters\n",
    "hyperparameter_optimization_results=hyperparameter_optimization_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Specify which hyperparameters to include in the plot labels\n",
    "plot_labels=['filter_nums_list', 'filter_sizes']\n",
    "\n",
    "# Plot the training curves\n",
    "plot_hyperparameter_optimization_run(\n",
    "    hyperparameter_optimization_results,\n",
    "    hyperparameters,\n",
    "    plot_labels,\n",
    "    accuracy_ylims=[45,75],\n",
    "    entropy_ylims=[0.01,20.0]\n",
    ").show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set some hyperparameters for the run\n",
    "hyperparameters={\n",
    "    'filter_nums': [128,256,512],\n",
    "    'filter_size': 6,\n",
    "    'l1_penalty': 0.001,\n",
    "    'l2_penalty': 0.01,\n",
    "    'image_width': 128,\n",
    "    'aspect_ratio': 4/3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.0001,\n",
    "    'epochs': 200\n",
    "}\n",
    "\n",
    "# Do a single training run\n",
    "training_results=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model performance\n",
    "\n",
    "### 4.1. Train model with final parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set some hyperparameters for the run\n",
    "hyperparameters={\n",
    "    'filter_nums': [128,256,512],\n",
    "    'filter_size': 6,\n",
    "    'l1_penalty': 0.002,\n",
    "    'l2_penalty': 0.02,\n",
    "    'image_width': 128,\n",
    "    'aspect_ratio': 4/3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.00005,\n",
    "    'epochs': 100,\n",
    "    'return_datasets': True\n",
    "}\n",
    "\n",
    "# Do a single training run\n",
    "training_results, training_dataset, validation_dataset=single_training_run(\n",
    "    training_data_path,\n",
    "    validation_data_path,\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_single_training_run(training_results).show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of testing dog and cat images\n",
    "testing_dogs=glob.glob(f'{testing_data_path}/dogs/dog.*')\n",
    "testing_cats=glob.glob(f'{testing_data_path}/cats/cat.*')\n",
    "\n",
    "# Plot some of the cat and dog images\n",
    "fig, axs=plt.subplots(3,2,figsize=(6, 4))\n",
    "\n",
    "for cat, dog, row in zip(testing_cats, testing_dogs, axs):\n",
    "    for animal, ax in zip([cat, dog], row):\n",
    "        animal=image.load_img(animal)\n",
    "        animal=image.img_to_array(animal)\n",
    "        animal/=255.0\n",
    "        ax.imshow(animal)\n",
    "        ax.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testing_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "    testing_data_path,\n",
    "    image_size=(128, int(128*(3/4))),\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images=np.concatenate([x for x, y in testing_dataset], axis=0)\n",
    "labels=np.concatenate([y for x, y in testing_dataset], axis=0)\n",
    "print(f'Testing images shape: {images.shape}')\n",
    "print(f'Testing labels shape: {labels.shape}')\n",
    "\n",
    "predictions=training_results.model.predict(images)\n",
    "\n",
    "threshold=0.5\n",
    "predictions=[1 if p > threshold else 0 for p in predictions]\n",
    "\n",
    "accuracy=accuracy_score(predictions, labels)*100\n",
    "print(f'Accuracy: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(labels, predictions, normalize='true')\n",
    "cm_disp=ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "_=cm_disp.plot()\n",
    "\n",
    "plt.title(f'Test set performance\\noverall accuracy: {accuracy:.1f}%')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 31148,
     "isSourceIdPinned": false,
     "sourceId": 3362,
     "sourceType": "competition"
    },
    {
     "datasetId": 7044555,
     "sourceId": 11269756,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
